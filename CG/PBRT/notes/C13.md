# C13. 蒙特卡洛积分 Monte Carlo Integeration

[TOC]

许多积分方程没有解析解，需要采用数值方法。尽管标准的数值积分方法如梯形积分和高斯求积能高效求解低维平滑积分，他们的收敛速度在高维和不连续积分时会变得糟糕。

蒙特卡罗数值积分法是解决这一问题的一种方法。他们利用随机性来计算积分，其收敛速度与被积函数的维数无关。

合理地使用随机性已经彻底改变了算法设计领域。随机算法可大致地分为两类

- Las Vegas：使用随机性，但最终结果相同。
- Monte Carlo：依赖于随机数，给出不同的结果，但平均上结果正确。

蒙特卡洛的一个非常有用的性质是，只要有能力计算被积函数 $f(x)$ 在域内任意点的值，就能估计积分 $\int f(x)\mathrm{d}x$。

渲染中遇到的许多积分很难或者不可能直接计算。而这些问题可以用蒙特卡洛积分来解决。

蒙特卡洛的主要缺点：如果用 n 个样本来估计积分，算法收敛到正确结果的速率是 $O(n^{-1/2})$。换句话说，如果要减少一半的误差，需要 4 倍的样本。

## 13.1 背景与概率回顾 Background and Probability Review

随机变量 $X$ 是一个从某个随机过程选择的值。一个函数作用在随机变量 $X$ 上得到新的随机变量 $Y=f(X)$。

采样离散随机变量 $X$，其满足 $p_i=P(X=X_i)$，我们可以用一个连续均匀分布的随机变量 $\xi\in[0,1)$，然后将其映射到离散随机变量上，选择 $X_i$ 如果
$$
\sum _ { j = 1 } ^ { i - 1 } p _ { j } < \xi \leq \sum _ { j = 1 } ^ { i } p _ { j }
$$
对于光照任务，概率基于功率，为
$$
p _ { i } = \frac { \Phi _ { i } } { \sum _ { j } \Phi _ { j } }
$$
随机变量的累积分布函数 cumulative distribution function (CDF) $P(x)$ 定义如下
$$
P ( x ) = \operatorname { Pr } \{ X \leq x \}
$$

### 13.1.1 连续随机变量 Continuous Random Variables

一个特别重要的随机变量是标准均匀随机变量 canonical uniform random variable，记为 $\xi$，在 $[0,1)$ 上等概率取值。

重要性体现在两方面

- 容易从软件层面实现这个随机变量
- 可以用该随机变量和适当的变换来生成任意分布的样本

概率分布函数 probability density function PDF 描述随机变量取特定值的相对概率，定义为
$$
p ( x ) = \frac { \mathrm { d } P ( x ) } { \mathrm { d } x }
$$
对于 $\xi$，我们有
$$
p ( x ) = \left\{ \begin{array} { l l } { 1 } & { x \in [ 0,1 ) } \\ { 0 } & { \text { otherwise } } \end{array} \right.
$$
PDFs 要求非负和定义域上积分值为 1。

区间概率
$$
P ( x \in [ a , b ] ) = \int _ { a } ^ { b } p ( x ) \mathrm { d } x
$$

### 13.1.2 期望和方差 Expected Values and Variance

函数 $f$ 的期望值 $E_p[f (x)]$ 定义为函数在其定义域上的某个值的分布 $p(x)$ 上的平均值。域 D 上的期望值定义为
$$
E _ { p } [ f ( x ) ] = \int _ { D } f ( x ) p ( x ) \mathrm { d } x
$$
函数的方差是函数与期望值的平方差的期望，即
$$
V [ f ( x ) ] = E \left[ ( f ( x ) - E [ f ( x ) ] ) ^ { 2 } \right]
$$
期望满足线性性
$$
\begin{aligned} E [ a f ( x ) ] & = a E [ f ( x ) ] \\ E \left[ \sum _ { i } f \left( X _ { i } \right) \right] & = \sum _ { i } E \left[ f \left( X _ { i } \right) \right] \end{aligned}
$$
方差满足
$$
\begin{aligned}
V [ a f ( x ) ] &= a ^ { 2 } V [ f ( x ) ]\\
\sum _ { i } V \left[ f \left( X _ { i } \right) \right] &= V \left[ \sum _ { i } f \left( X _ { i } \right) \right]\\
V [ f ( x ) ] &= E \left[ ( f ( x ) ) ^ { 2 } \right] - E [ f ( x ) ] ^ { 2 }\\
\end{aligned}
$$

## 13.2 蒙特卡洛估计 the Monte Carlo Estimator

假设我们要计算 1D 积分 $\int _ { a } ^ { b } f ( x ) \mathrm { d } x$。给定一组均匀随机变量 $X_i\in[a,b]$，蒙特卡洛估计表明估计式
$$
F _ { N } = \frac { b - a } { N } \sum _ { i = 1 } ^ { N } f \left( X _ { i } \right)
$$
的期望值 $E[F_N]$ 等于积分值。

> **推导** 
>
> 已知随机变量 $X_i$ 的 PDF $p(x)=1/(b-a)$，可推得
> $$
> \begin{aligned} E \left[ F _ { N } \right] & = E \left[ \frac { b - a } { N } \sum _ { i = 1 } ^ { N } f \left( X _ { i } \right) \right] \\ & = \frac { b - a } { N } \sum _ { i = 1 } ^ { N } E \left[ f \left( X _ { i } \right) \right] \\ & = \frac { b - a } { N } \sum _ { i = 1 } ^ { N } \int _ { a } ^ { b } f ( x ) p ( x ) \mathrm { d } x \\ & = \frac { 1 } { N } \sum _ { i = 1 } ^ { N } \int _ { a } ^ { b } f ( x ) \mathrm { d } x \\ & = \int _ { a } ^ { b } f ( x ) \mathrm { d } x \end{aligned}
> $$

对均匀随机变量的限制可以用一个小的泛化来放宽。这是非常重要的一步，因为在蒙特卡罗中，仔细选择抽取样本的PDF是减少方差的一项重要技术。

如果随机变量 $X_i$ 服从某任意 PDF $p(x)$，则估计式
$$
F _ { N } = \frac { 1 } { N } \sum _ { i = 1 } ^ { N } \frac { f \left( X _ { i } \right) } { p \left( X _ { i } \right) }
$$
的期望 $E \left[ F _ { N } \right]$ 是积分值，要求当 $f(x)\ne 0$ 时 $p(x)>0$。

> **推导** 
> $$
> \begin{aligned} E \left[ F _ { N } \right] & = E \left[ \frac { 1 } { N } \sum _ { i = 1 } ^ { N } \frac { f \left( X _ { i } \right) } { p \left( X _ { i } \right) } \right] \\ & = \frac { 1 } { N } \sum _ { i = 1 } ^ { N } \int _ { a } ^ { b } \frac { f ( x ) } { p ( x ) } p ( x ) \mathrm { d } x \\ & = \frac { 1 } { N } \sum _ { i = 1 } ^ { N } \int _ { a } ^ { b } f ( x ) \mathrm { d } x \\ & = \int _ { a } ^ { b } f ( x ) \mathrm { d } x \end{aligned}
> $$

## 13.3 采样随机变量 Samping Random Variables

### 13.3.1 反演方法 the Inversion Method

反演方法使用一个或多个均匀随机变量，并将它们映射成服从期望分布的随机变量。

采样服从 PDF $p(x)$ 的 $X_i$ 的步骤

1. 计算 CDF $P(x)=\int_{-\infty}^x p(x')dx'$ 
2. 计算逆函数 $p^{-1}(x)$ 
3. 获取均匀分布的随机数 $\xi$ 
4. 计算 $X_i=P^{-1}(\xi)$ 

#### 示例：分段常数 1D 函数 Example: Piecewise-Constant 1D Functions

![1557142569174](assets/1557142569174.png)

每段长度 $\Delta=1/N$。积分值为
$$
c = \int _ { 0 } ^ { 1 } f ( x ) \mathrm { d } x = \sum _ { i = 0 } ^ { N - 1 } \Delta v _ { i } = \sum _ { i = 0 } ^ { N - 1 } \frac { v _ { i } } { N }
$$
这样 PDF $p(x)=f(x)/c$。因此 CDF $P(x)$ 为
$$
\begin{aligned}
P \left( x _ { 0 } \right) & = 0 \\

P \left( x _ { 1 } \right) & = \int _ { x _ { 0 } } ^ { x _ { 1 } } p ( x ) \mathrm { d } x = \frac { v _ { 0 } } { N c } = P \left( x _ { 0 } \right) + \frac { v _ { 0 } } { N c } \\

P \left( x _ { 2 } \right) & = \int _ { x _ { 0 } } ^ { x _ { 2 } } p ( x ) \mathrm { d } x = \int _ { x _ { 0 } } ^ { x _ { 1 } } p ( x ) \mathrm { d } x + \int _ { x _ { 1 } } ^ { x _ { 2 } } p ( x ) \mathrm { d } x = P \left( x _ { 1 } \right) + \frac { v _ { 1 } } { N c } \\

P \left( x _ { i } \right) & = P \left( x _ { i - 1 } \right) + \frac { v _ { i - 1 } } { N c }
\end{aligned}
$$
在两点 $x_i$ 和 $x_{i+1}$ 间，CDF 以斜率 $v_i/c$ 线性增加。

![1557142777793](assets/1557142777793.png)

由此我们可以利用反演方法去采样。

### 13.3.2 拒绝方法 the Rejection Method

对于有些函数 $f(x)$，难以积分它们来得到 PDFs，或者难以求逆 CDFs。拒绝方法只要求我们知道如何采样服从 PDF $p(x)$ 的随机变量，以及要求存在 $c$，使得 $f(x)<c\ p(x)$。算法如下

![1557133611082](assets/1557133611082.png)

拒绝方法并没有用在 `pbrt` 的蒙特卡洛算法里，一般更喜欢采样直接采样的方法。但这也是一个值得注意的重要方法。

## *13.4 大都市采样 Metropolis Sampling

## 13.5 分布变换 Transforming between Distributions

给定一个服从 PDF $p_x(x)$ 的随机变量 $X_i$，我们想知道随机变量 $Y_i=y(X_i)$ 的分布。函数 $y(x)$ 必须是单射的。即 y 的导数必须严格大于 0（或严格小于 0），意味着
$$
Pr\{Y\le y(x)\}=Pr\{X\le x\}
$$
即
$$
P_y(y)=P_y(y(x))=P_x(x)
$$
由 PDF 的定义可得微分关系为
$$
p_y(y)=\left|\frac{\mathrm{d}y}{\mathrm{d}x}\right|^{-1}p_x(x)
$$
已知 $X$ 服从 PDF $p_x(x)$，$Y$ 服从 PDF $p_y(y)$，要求累计分布函数相等，即 $P_y(y) = P_x(x)$，则
$$
y(x)=P_y^{-1}(P_x(x))
$$
如果 $X$ 是 $[0,1)$ 上均匀分布的随机变量，则 $P_x(x)=x$，这样我们就得到了 13.3.1 节给出的步骤。

### 13.5.1 多维变换 Transformation in Multiple Dimensions

假设我们有一个 n 维随机变量 $X$，其概率密度函数为 $p_x(x)$，令 $Y=T(X)$，且 $T$ 是一个双射，这样有
$$
p _ { y } ( y ) = p _ { y } ( T ( x ) ) = \frac { p _ { x } ( x ) } { \left| J _ { T } ( x ) \right| }
$$
其中 $T ( x ) = \left( T _ { 1 } ( x ) , \ldots , T _ { n } ( x ) \right)$，$|J_T|$ 是 $T$ 的雅克比矩阵的行列式的绝对值，雅克比矩阵如下
$$
\left( \begin{array} { c c c } { \partial T _ { 1 } / \partial x _ { 1 } } & { \cdots } & { \partial T _ { 1 } / \partial x _ { n } } \\ { \vdots } & { \ddots } & { \vdots } \\ { \partial T _ { n } / \partial x _ { 1 } } & { \cdots } & { \partial T _ { n } / \partial x _ { n } } \end{array} \right)
$$

### 13.5.2 极坐标 Polar Coordinates

极坐标变换为
$$
\begin{array} { l } { x = r \cos \theta } \\ { y = r \sin \theta } \end{array}
$$
假设我们从 $p(r,\theta)$ 中采样，想知道 $p(x,y)$，雅克比矩阵为
$$
J _ { T } = \left( \begin{array} { c c } { \frac { \partial x } { \partial r } } & { \frac { \partial x } { \partial \theta } } \\ { \frac { \partial y } { \partial r } } & { \frac { \partial y } { \partial \theta } } \end{array} \right) = \left( \begin{array} { c c } { \cos \theta } & { - r \sin \theta } \\ { \sin \theta } & { r \cos \theta } \end{array} \right)
$$
其行列式为 $r \left( \cos ^ { 2 } \theta + \sin ^ { 2 } \theta \right) = r$，因此 $p ( x , y ) = p ( r , \theta ) / r$。当然，这个与我们期望的相反了——通常我们从笛卡尔坐标采样然后变换它到极坐标中。这样我们有
$$
p ( r , \theta ) = r\ p ( x , y )
$$

### 13.5.3 球坐标 Spherical Coordinates

球坐标变换为
$$
\begin{aligned} x & = r \sin \theta \cos \phi \\ y & = r \sin \theta \sin \phi \\ z & = r \cos \theta \end{aligned}
$$
可求得 $\left| J _ { T } \right| = r ^ { 2 } \sin \theta$，相应的概率密度函数为
$$
p ( r , \theta , \phi ) = r ^ { 2 } \sin \theta p ( x , y , z )
$$

## 13.6 多维变换的二维采样 2D Sampling with Multidimensional Transformations

假设我们要采样服从 $p(x,y)$ 的 $(X,Y)$。有时多为目的是可分的 $p ( x , y ) = p _ { x } ( x ) p _ { y } ( y )$，这样可以分别采样。

给定一个 2D 密度函数，边际密度函数 $p(x)$ 为
$$
p ( x ) = \int p ( x , y ) \mathrm { d } y
$$
条件密度函数 $p ( y | x )$ 为
$$
p ( y | x ) = \frac { p ( x , y ) } { p ( x ) }
$$
从联合分布中进行 2D 采样的基本思想是首先计算边际密度，以分离一个特定的变量，然后使用标准 1D 采样技术从该密度中采样。一旦得到该采样，就可以计算给定值的条件密度函数并从该分布中采样，同样使用标准的 1D 采样技术。

### 13.6.1 半球均匀采样 Uniformly Sampling a Hemisphere

我们要在半球上关于立体角均匀采样，则有 $p(\omega)=c$。

根据 PDF 的性质，有
$$
\begin{aligned}
\int _ { \mathcal { H } ^ { 2 } } p ( \omega ) \mathrm { d } \omega &= 1\\
c \int _ { \mathcal { H } ^ { 2 } } \mathrm { d } \omega &= 1\\
c &= \frac { 1 } { 2 \pi }\\
\end{aligned}
$$
则 $p ( \omega ) = 1 / ( 2 \pi )$ 或 $p ( \theta , \phi ) = \sin \theta / ( 2 \pi )$。

注意，这个密度函数是可分的，但下边用边际和条件密度来说明多维采样技术。

首先采样 $\theta$，我们需要边际密度函数 $p(\theta)$ 
$$
p ( \theta ) = \int _ { 0 } ^ { 2 \pi } p ( \theta , \phi ) \mathrm { d } \phi = \int _ { 0 } ^ { 2 \pi } \frac { \sin \theta } { 2 \pi } \mathrm { d } \phi = \sin \theta
$$
然后计算 $\phi$ 的条件密度函数
$$
p ( \phi | \theta ) = \frac { p ( \theta , \phi ) } { p ( \theta ) } = \frac { 1 } { 2 \pi }
$$
现在我们使用 1D 反演技术来各自采样
$$
\begin{aligned} P ( \theta ) & = \int _ { 0 } ^ { \theta } \sin \theta ^ { \prime } \mathrm { d } \theta ^ { \prime } = 1 - \cos \theta \\ P ( \phi | \theta ) & = \int _ { 0 } ^ { \phi } \frac { 1 } { 2 \pi } \mathrm { d } \phi ^ { \prime } = \frac { \phi } { 2 \pi } \end{aligned}
$$
求逆，并用 $\xi$ 去替代 $1-\xi$ 
$$
\begin{aligned} \theta & = \cos ^ { - 1 } \xi _ { 1 } \\ \phi & = 2 \pi \xi _ { 2 } \end{aligned}
$$
再将他们转换为笛卡尔坐标
$$
\begin{aligned} x & = \sin \theta \cos \phi = \cos \left( 2 \pi \xi _ { 2 } \right) \sqrt { 1 - \xi _ { 1 } ^ { 2 } } \\ y & = \sin \theta \sin \phi = \sin \left( 2 \pi \xi _ { 2 } \right) \sqrt { 1 - \xi _ { 1 } ^ { 2 } } \\ z & = \cos \theta = \xi _ { 1 } \end{aligned}
$$
另外我们需要计算 PDF，要注意是哪个 PDF（如关于立体角 $\omega$，关于 $(\theta,\phi)$）。对于所有的方向采样，我们需要的都是关于立体角的 PDF。所以结果为 $1/(2\pi)$。

整个球面上采样也类似
$$
\begin{aligned} x & = \cos \left( 2 \pi \xi _ { 2 } \right) \sqrt { 1 - z ^ { 2 } } = \cos \left( 2 \pi \xi _ { 2 } \right) 2 \sqrt { \xi _ { 1 } \left( 1 - \xi _ { 1 } \right) } \\ y & = \sin \left( 2 \pi \xi _ { 2 } \right) \sqrt { 1 - z ^ { 2 } } = \sin \left( 2 \pi \xi _ { 2 } \right) 2 \sqrt { \xi _ { 1 } \left( 1 - \xi _ { 1 } \right) } \\ z & = 1 - 2 \xi _ { 1 } \end{aligned}
$$
PDF 为 $1/4\pi$。

### 13.6.2 单位圆盘上采样 Samping a Unit Disk

直觉上的 $r = \xi _ { 1 } , \theta = 2 \pi \xi _ { 2 }$ 是不均匀采样。

![1557138995302](assets/1557138995302.png)

关于面积均匀采样，因此 $p(x,y)=c$，通过标准化可知，$p(x,y)=1/\pi$。将其转换为极坐标，有 $p ( r , \theta ) = r / \pi$。计算下边际和条件概率分布
$$
\begin{aligned} p ( r ) & = \int _ { 0 } ^ { 2 \pi } p ( r , \theta ) \mathrm { d } \theta = 2 r \\ p ( \theta | r ) & = \frac { p ( r , \theta ) } { p ( r ) } = \frac { 1 } { 2 \pi } \end{aligned}
$$
计算 $P(r)$，$P^{-1}(r)$，$P(\theta)$ 和 $P^{-1}(\theta)$，得到
$$
\begin{aligned} r & = \sqrt { \xi _ { 1 } } \\ \theta & = 2 \pi \xi _ { 2 } \end{aligned}
$$
![1557139229425](assets/1557139229425.png)

尽管这个映射解决了均匀的问题，但它扭曲了区域（单位正方形被拉长和/或压扁到圆盘上）。

![1557139773236](assets/1557139773236.png)

一个更好的方法是“同心”映射，将单位正方形变成单位圆。它将 $[-1,1]^2$ 上的点映射到单位圆盘上通过均匀的映射同心正方形到同心圆。

![1557140043318](assets/1557140043318.png)

对于上图阴影部分，有
$$
\begin{aligned} r & = x \\ \theta & = \frac { y } { x } \frac { \pi } { 4 } \end{aligned}
$$
![1557140764959](assets/1557140764959.png)

不同部分对应的公式不同。

### 13.6.3 余弦加权半球采样 Cosine-Weighted Hemisphere Sampling

要求 $p ( \omega ) \propto \cos \theta$，标准化
$$
\begin{aligned}
\int _ { \mathcal { H } ^ { 2 } } p ( \omega ) \mathrm { d } \omega & = 1 \\
\int _ { 0 } ^ { 2 \pi } \int _ { 0 } ^ { \frac { \pi } { 2 } } c \cos \theta \sin \theta \mathrm { d } \theta \mathrm { d } \phi & = 1 \\
c \  2 \pi \int _ { 0 } ^ { \pi / 2 } \cos \theta \sin \theta \mathrm { d } \theta & = 1 \\
c & = \frac { 1 } { \pi }
\end{aligned}
$$
则
$$
p ( \theta , \phi ) = \frac { 1 } { \pi } \cos \theta \sin \theta
$$
我们可以计算边际和条件密度，可以使用 Malley 方法来生成 cosine-weighted 点。该方法的思想是，我们均匀的在单位圆盘上采样，然后将其投影到半球面上即可，得到的方向分布就是余弦分布的。

![1557141707836](assets/1557141707836.png)

> 证明
>
> 记 $(r,\phi)$ 为圆盘上的极坐标，有 $p(r,\phi)=r/\pi$。投影后 $\sin\theta=r$。为了完成变换 $( r , \phi ) = ( \sin \theta , \phi ) \rightarrow ( \theta , \phi )$，我们需要雅克比行列式
> $$
> \left| J _ { T } \right| = \left| \begin{array} { c c } { \cos \theta } & { 0 } \\ { 0 } & { 1 } \end{array} \right| = \cos \theta
> $$
> 因此
> $$
> p ( \theta , \phi ) = \left| J _ { T } \right| p ( r , \phi ) = \cos \theta \frac { r } { \pi } = ( \cos \theta \sin \theta ) / \pi
> $$

这个方法不要求具体的圆盘采样方法，我们可以使用之前的同心映射或者简单的 $( r , \theta ) = \left( \sqrt { \xi _ { 1 } } , 2 \pi \xi _ { 2 } \right)$。

相应的 PDF 为 $\cos\theta/\pi$。

### 13.6.4 圆锥采样 Sampling a Cone

### 13.6.5 三角形采样 Sampling a Triangle

### *13.6.6 相机采样 Sampling Cameras

### 13.6.7 分段常数 2D 分布 Piecewise-Constant 2D Distributions

考虑一个 2D 函数 $f(u,v)$，它由$n_u\times n_v$ 个值的 $f[u_i,v_j]$ 定义，其中 $u _ { i } \in \left[ 0,1 , \ldots , n _ { u } - 1 \right] , v _ { j } \in \left[ 0,1 , \ldots , n _ { v } - 1 \right]$，且 $f[u_i,v_j]$ 给出了 $f(x)$ 在区间 $\left[ i / n _ { u } , ( i + 1 ) / n _ { u } \right) \times \left[ j / n _ { v } , ( j + 1 ) / n _ { v } \right)$ 上的常数值。

用 $( \tilde { u } , \tilde { v } )$ 记作 $(u_i,v_j)$ 相应的离散值，有 $\tilde { u } = \left\lfloor n _ { u } u \right\rfloor$ 和 $\tilde { v } = \left\lfloor n _ { v } v \right\rfloor$，则有
$$
f ( u , v ) = f [ \tilde { u } , \tilde { v } ]
$$
积分值为
$$
I _ { f } = \iint f ( u , v ) \mathrm { d } u \mathrm { d } v = \frac { 1 } { n _ { u } n _ { v } } \sum _ { i = 0 } ^ { n _ { u } - 1 } \sum _ { j = 0 } ^ { n _ { v } - 1 } f \left[ u _ { i } , v _ { j } \right]
$$
得到 PDF
$$
p ( u , v ) = \frac { f ( u , v ) } { \iint f ( u , v ) \mathrm { d } u \mathrm { d } v } = \frac { f [ \tilde { u } , \tilde { v } ] } { 1 / \left( n _ { u } n _ { v } \right) \sum _ { i } \sum _ { j } f \left[ u _ { i } , v _ { j } \right] }
$$
边际密度分布 $p(v)$ 为
$$
p ( v ) = \int p ( u , v ) \mathrm { d } u = \frac { \left( 1 / n _ { u } \right) \sum _ { i } f \left[ u _ { i } , \tilde { v } \right] } { I _ { f } }
$$
这是一个分段常数 1D 函数，13.3.1 节有说明采样方法。

条件密度分布 $p(u|v)$ 为
$$
p ( u | v ) = \frac { p ( u , v ) } { p ( v ) } = \frac { f [ \tilde { u } , \tilde { v } ] / I _ { f } } { p [ \tilde { v } ] }
$$
给定一个特定的 $\tilde{v}$，$p[\tilde{u}|\tilde{v}]$ 是一个分段常数 1D 函数，总共有 $n_v$ 个这样的 1D 条件密度。

采样的过程分 2 步，先采样 v，然后选出特定的条件分布，再采样 u。两个 pdf 相乘得到联合的 pdf。

时间复杂度为 $O(\log n_u \log n_v)$，空间复杂度为 $O(n_u n_v)$。

> 可以用 Alias Method 算法将时间复杂度减为 $O(1)$，空间复杂度还是 $O(n_u n_v)$。

## 13.7 俄罗斯轮盘赌和分裂 Rissian Roulette and Spitting

## 13.8 仔细的样本布置 Careful Sample Placement

## 13.9 偏差 Bias

## 13.10 重要性采样 Importance Samping

