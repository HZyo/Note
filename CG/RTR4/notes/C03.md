# C03. 图形处理单元 The Graphics Processing Unit

[TOC]

## 3.1 数据并行架构 Data-Parallel Architectures

CPU 被优化用于处理各种数据结构和大型代码库，有多个核心，但每核几乎都以串行方式跑代码，除了 SIMD。通过快速的局部缓存 cache memory 减少延迟 latency，通过分支预测、指令重排、寄存器重命名和缓冲预取来减少停顿 stall。

而 GPU 的大部分芯片区域是一大组处理器，称为着色器核心，经常有数千个。GPU 是一个流处理器，依次处理相似数据的有序集。由于数据的相似性（如顶点集合），GPU 可以大量并行的方式处理数据。另外，这些调用应尽可能独立，不需要邻近调用的信息，也不共享可写内存位置。这个规则有时会被打破，以允许新的和有用的功能，但是这种例外是以潜在的延迟为代价的，因为一个处理器可能会等待另一个处理器完成它的工作。

GPU 为吞吐量 throughput 优化，吞吐量是数据处理的最大速率。快速处理是有代价的，较少的芯片用于缓存和控制逻辑，比 CPU 延迟高很多。

寄存器是局部的，可快速访问，没有延迟。纹理是独立的资源，不是像素程序局部存储的一部分。一个内存获取 fetch 会消耗成百上千个时钟周期，使得程序停顿 stall。每个片元有自己的局部寄存器，着色器处理器可以切换并执行其他片元而不用停顿在纹理获取上，这个切换十分快速。多次切换后最终回到第一个片元时，纹理获取就完成了。单个片元的执行时间很长，但通过切换，总体执行时间不多。

GPU 通过切换片元隐藏了延迟。进一步地，GPU 将指令逻辑从数据分离，称为 single instruction multipe data SIMD，在固定数量的着色器程序上 lock-step 执行相同的命令。SIMD 可以节省大量的硅和功率。

片元的每一像素着色器调用称为一个线程 thread，不用于 CPU 的线程，包含输入数据的存储空间和一些寄存器。使用相同着色器程序的线程绑在一组里，称为 wraps（NVIDIA）和 wavefronts（AMD）。一个 wrap/wavefront 由 8-64 个 GPU 着色器核心执行，使用了 SIMD，每个线程是一个 SIMD 车道 lane。

> 示例
>
> 有 2000 个线程，NVIDIA 的 wrap 有 32 线程，$2000/32=62.5$ wraps，这样需要 63 个 wraps，其中一个 wrap 有一半是空的。32个处理器 lock-step 执行着色器程序。当遇到内存获取时，所有的线程都同时如此，因为相同的所有线程都执行着相同的指令。该 wrap 会与另一 wrap 交换，而不是停顿，交换速度也很快。每个 thread 有自己的寄存器并且 wrap 记录了正在执行的指令。交换只是将一组核心指向另一组线程，没有其他开销。

> 示例
>
> ![1559188874181](assets/1559188874181.jpg)

还有很多技术用于优化[^945]，但 wrap-swapping 是主要的延迟隐藏机制。

着色器程序的结构也是影响效率的一个重要因素。主要的因素是线程所需的寄存器数量。需要越多的寄存器，则更少的线程 / wrap 可驻留在 GPU 上，意味着停顿没法通过交换来缓和。驻留的 wraps 称为 "in flight"，数量称为 occupancy。相关的细节讨论可见[^993][^1911][^1914]。

另一影响因素是动态分支 dynamic branching，由 if 和 loop 语句造成。当遇到 if 语句时，如果所有的线程都走同一分支，wrap 能继续执行而不需要管另一分支。然而如果有线程需要走另一分支，则 wrap 必须执行两个分支，扔掉对特定分支不需要的结果[^529][^945]，该问题称为线程分叉 thread divergence，少部分线程需要执行 loop 或 if 而 wrap 中其他线程不需要，导致它们等待。

## 3.2 GPU 管线概览 GPU Pipeline Overview

## 3.3 可编程着色器阶段 The Programmable Shader Stage

## 3.4 可编程着色和 API 的发展 The Evolution of Programmable Shading and APIs

## 3.5 顶点着色器 The Vertex Shader

## 3.6 曲面细分阶段 The Tessellation Stage

## 3.7 几何着色器 The Geometry Shader

## 3.8 像素着色器 The Pixel Shader

## 3.9 合并阶段 The Merging Stage

## 3.10 计算着色器 The Compute Shader

## 参考

[^529]: Giesen, Fabian, "**View Frustum Culling**," The ryg blog, Oct. 17, 2010. Cited on p. 983, 986

[^945]: Kubisch, Christoph, "[**Life of a Triangle—NVIDIA’s Logical Pipeline**](https://developer.nvidia.com/content/life-triangle-nvidias-logical-pipeline)," NVIDIA GameWorks blog, Mar. 16, 2015. Cited on p. 32

[^993]: Lauritzen, Andrew, "**Future Directions for Compute-for-Graphics**," SIGGRAPH Open Problems in Real-Time Rendering course, Aug. 2017. Cited on p. 32, 812, 908

[^1911]: Wronski, Bartlomiej,  "**Assassin’s Creed: Black Flag—Road to Next-Gen Graphics**," Game Developers Conference, Mar. 2014. Cited on p. 32, 218, 478, 571, 572, 801

[^1914]: Wronski, Bartlomiej, "**GCN—Two Ways of Latency Hiding and Wave Occupancy**," Bart Wronski blog, Mar. 27, 2014. Cited on p. 32, 801, 1005

