# C03. 图形处理单元 The Graphics Processing Unit

[TOC]

## 3.1 数据并行架构 Data-Parallel Architectures

CPU 被优化用于处理各种数据结构和大型代码库，有多个核心，但每核几乎都以串行方式跑代码，除了 SIMD。通过快速的局部缓存 cache memory 减少延迟 latency，通过分支预测、指令重排、寄存器重命名和缓冲预取来减少停顿 stall。

而 GPU 的大部分芯片区域是一大组处理器，称为着色器核心，经常有数千个。GPU 是一个流处理器，依次处理相似数据的有序集。由于数据的相似性（如顶点集合），GPU 可以大量并行的方式处理数据。另外，这些调用应尽可能独立，不需要邻近调用的信息，也不共享可写内存位置。这个规则有时会被打破，以允许新的和有用的功能，但是这种例外是以潜在的延迟为代价的，因为一个处理器可能会等待另一个处理器完成它的工作。

GPU 为吞吐量 throughput 优化，吞吐量是数据处理的最大速率。快速处理是有代价的，较少的芯片用于缓存和控制逻辑，比 CPU 延迟高很多。

寄存器是局部的，可快速访问，没有延迟。纹理是独立的资源，不是像素程序局部存储的一部分。一个内存获取 fetch 会消耗成百上千个时钟周期，使得程序停顿 stall。每个片元有自己的局部寄存器，着色器处理器可以切换并执行其他片元而不用停顿在纹理获取上，这个切换十分快速。多次切换后最终回到第一个片元时，纹理获取就完成了。单个片元的执行时间很长，但通过切换，总体执行时间不多。

GPU 通过切换片元隐藏了延迟。进一步地，GPU 将指令逻辑从数据分离，称为 single instruction multipe data SIMD，在固定数量的着色器程序上 lock-step 执行相同的命令。SIMD 可以节省大量的硅和功率。

片元的每一像素着色器调用称为一个线程 thread，不用于 CPU 的线程，包含输入数据的存储空间和一些寄存器。使用相同着色器程序的线程绑在一组里，称为 wraps（NVIDIA）和 wavefronts（AMD）。一个 wrap/wavefront 由 8-64 个 GPU 着色器核心执行，使用了 SIMD，每个线程是一个 SIMD 车道 lane。

> 示例
>
> 有 2000 个线程，NVIDIA 的 wrap 有 32 线程，$2000/32=62.5$ wraps，这样需要 63 个 wraps，其中一个 wrap 有一半是空的。32个处理器 lock-step 执行着色器程序。当遇到内存获取时，所有的线程都同时如此，因为相同的所有线程都执行着相同的指令。该 wrap 会与另一 wrap 交换，而不是停顿，交换速度也很快。每个 thread 有自己的寄存器并且 wrap 记录了正在执行的指令。交换只是将一组核心指向另一组线程，没有其他开销。

> 示例
>
> ![1559188874181](assets/1559188874181.jpg)

还有很多技术用于优化[^945]，但 wrap-swapping 是主要的延迟隐藏机制。

着色器程序的结构也是影响效率的一个重要因素。主要的因素是线程所需的寄存器数量。需要越多的寄存器，则更少的线程 / wrap 可驻留在 GPU 上，意味着停顿没法通过交换来缓和。驻留的 wraps 称为 "in flight"，数量称为 occupancy。相关的细节讨论可见[^993][^1911][^1914]。

另一影响因素是动态分支 dynamic branching，由 if 和 loop 语句造成。当遇到 if 语句时，如果所有的线程都走同一分支，wrap 能继续执行而不需要管另一分支。然而如果有线程需要走另一分支，则 wrap 必须执行两个分支，扔掉对特定分支不需要的结果[^529][^945]，该问题称为线程分叉 thread divergence，少部分线程需要执行 loop 或 if 而 wrap 中其他线程不需要，导致它们等待。

## 3.2 GPU 管线概览 GPU Pipeline Overview

GPU 实现了几何处理，光栅化和像素处理管线阶段，它们分成了接个硬件阶段，有着不同的可配置性或可编程性。

![1559191353721](assets/1559191353721.jpg)

> 绿色代表可编程，虚线是可选的，黄色是可配置的，蓝色是固定的

程序员通过 API 可了解到 GPU 的逻辑模型 logical model，而作为逻辑模型实现的物理模型 physical model 取决于硬件供应商。逻辑模型中固定功能的阶段可能通过向 GPU 中邻接的可编程阶段添加指令来实现。管道中的单个程序可以被分割成由单独的子单元执行的元素，或者完全由单独的 pass 执行。逻辑模型可以帮助推断影响性能的因素，但其与 GPU 中实际实现有区别。

顶点着色器是可编程阶段，用于实现几何处理阶段。几何着色器是可编程阶段，处理原型（点、线、三角形）的顶点，可销毁或者创建新的原型。曲面细分阶段和几何着色器是可选的，不是所有 GPU 都支持，特别是移动设备。

## 3.3 可编程着色器阶段 The Programmable Shader Stage

现代着色器程序使用了统一的着色器设计，顶点、像素、几何和曲面细分着色器共享了一个边长模型，内部使用相同的指令集架构 instruction set architecture ISA。实现了该模型的处理器称为 common-shader core（DirectX），背后的思想是着色器处理器可以承担多种角色。

着色器编程使用的是 C-like 着色语言如 DirectX 的 High-Level Shading Language（HLSL）和 OpenGL Shading Language（GLSL）。DirectX 的 GLSL 能编译成虚拟机字节码，称为 intermediate language（IL 或 DXIL），提供硬件独立性。中间表示允许着色器程序被离线编译并存储，可以被驱动转换成特定 GPU 的 ISA。

基础的数据类型是 32 位单精度浮点标量和向量（只存在于代码中，硬件上不支持），现代 GPU 也原生支持 32 位整数和 64 位浮点数。聚合类型（如结构，数组，矩阵）也是支持的。

一个 draw call 调用 API 画一组原型，使得图形管线执行着色器。输入有两个类型，为 uniform（一个 draw call 中保持常量，draw call 间可修改）和 varying 输入（来自三角形顶点或光栅化的数据）。纹理是一种特殊的 uniform 输入，曾经总是表面颜色图像，闲杂可以看成是数据的任意大数组。

底层的虚拟机为不同类型的数据提供了不同的寄存器。用于 uniform 的 constant register 数量大大多于用于 varring 的寄存器。这是因为 varing 数据对于每个顶点或像素要分别存储，而 uniform 数据在 draw call 内的顶点和像素间共享。虚拟机还具有通用 general-purpose 的临时寄存器 temporary registers，作为暂存空间。

![1559196093206](assets/1559196093206.jpg)

GPU 常用的操作通过运算符（如 + 和 *）表示。其余部分通过内置函数 intrinsic functions （如 `atan`, `sqrt`）表示。

着色器支持两种流控制 flow control。静态流控制 static flow control 基于 uniform 进行分支，不会发生线程分叉。动态流控制 Dynamic flow control 基于 varing 进行分支，表达能力强于静态流控制，但开销更大。

## 3.4 可编程着色和 API 的发展 The Evolution of Programmable Shading and APIs

## 3.5 顶点着色器 The Vertex Shader

## 3.6 曲面细分阶段 The Tessellation Stage

## 3.7 几何着色器 The Geometry Shader

## 3.8 像素着色器 The Pixel Shader

## 3.9 合并阶段 The Merging Stage

## 3.10 计算着色器 The Compute Shader

## 参考

[^529]: Giesen, Fabian, "**View Frustum Culling**," The ryg blog, Oct. 17, 2010. Cited on p. 983, 986

[^945]: Kubisch, Christoph, "[**Life of a Triangle—NVIDIA’s Logical Pipeline**](https://developer.nvidia.com/content/life-triangle-nvidias-logical-pipeline)," NVIDIA GameWorks blog, Mar. 16, 2015. Cited on p. 32

[^993]: Lauritzen, Andrew, "**Future Directions for Compute-for-Graphics**," SIGGRAPH Open Problems in Real-Time Rendering course, Aug. 2017. Cited on p. 32, 812, 908

[^1911]: Wronski, Bartlomiej,  "**Assassin’s Creed: Black Flag—Road to Next-Gen Graphics**," Game Developers Conference, Mar. 2014. Cited on p. 32, 218, 478, 571, 572, 801

[^1914]: Wronski, Bartlomiej, "**GCN—Two Ways of Latency Hiding and Wave Occupancy**," Bart Wronski blog, Mar. 27, 2014. Cited on p. 32, 801, 1005

