# 01_01 1+1

本章介绍TensorFlow的基本操作。

前置知识：

- [Python基本操作](http://www.runoob.com/python3/python3-tutorial.html) （赋值、分支及循环语句、使用import导入库）；
- [Python的With语句](https://www.ibm.com/developerworks/cn/opensource/os-cn-pythonwith/index.html) ；
- [NumPy](https://docs.scipy.org/doc/numpy/user/quickstart.html) ，Python下常用的科学计算库。TensorFlow与之结合紧密；
- [向量](https://zh.wikipedia.org/wiki/%E5%90%91%E9%87%8F) 和 [矩阵](https://zh.wikipedia.org/wiki/%E7%9F%A9%E9%98%B5) 运算；
- [函数的导数](http://old.pep.com.cn/gzsx/jszx_1/czsxtbjxzy/qrzptgjzxjc/dzkb/dscl/) ，[多元函数求导](https://zh.wikipedia.org/wiki/%E5%81%8F%E5%AF%BC%E6%95%B0) ；
- [线性回归](http://old.pep.com.cn/gzsx/jszx_1/czsxtbjxzy/qrzptgjzxjc/dzkb/dscl/) ；
- [梯度下降方法](https://zh.wikipedia.org/wiki/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95) 求函数的局部最小值。

``` python
import tensorflow as tf
tf.enable_eager_execution()
```

## 1. 科学计算库

我们可以先简单地将TensorFlow视为一个科学计算库（类似于Python下的NumPy）。这里以计算 $1+1$ 和 $\left[ \begin{array} { l l } { 1 } & { 2 } \\ { 3 } & { 4 } \end{array} \right] \times \left[ \begin{array} { l l } { 5 } & { 6 } \\ { 7 } & { 8 } \end{array} \right]$ 作为Hello World的示例。

```python
a = tf.constant(1)
b = tf.constant(1)
c = tf.add(a, b)    # 也可以直接写 c = a + b，两者等价

# tf.Tensor(2, shape=(), dtype=int32)
print(c)

A = tf.constant([[1, 2], [3, 4]])
B = tf.constant([[5, 6], [7, 8]])
C = tf.matmul(A, B)

# tf.Tensor(
#[[19 22]
# [43 50]], shape=(2, 2), dtype=int32)
print(C)
```

以上代码声明了 `a`、`b`、`A`、`B` 四个 **张量** （Tensor），并使用了 `tf.add()` 和 `tf.matmul()` 两个 **操作** （Operation）对张量进行了加法和矩阵乘法运算，运算结果即时存储于 `c`、`C` 两个张量内。张量的重要属性是其**形状**（shape）和**类型**（dtype）。这里 `a`、`b`、`c` 是纯量，形状为空，类型为int32；`A`、`B`、`C` 为2×2的矩阵，形状为 `(2, 2)`，类型为int32。

## 2. 自动求导

在机器学习中，我们经常需要计算函数的导数。TensorFlow提供了强大的 **自动求导机制** 来计算导数。以下代码展示了如何使用 `tf.GradientTape()` 计算函数 $y(x)=x^2$ 在 $x=3​$ 时的导数：

```python
x = tf.get_variable('x', shape=[1], initializer=tf.constant_initializer(3.))

# 在 tf.GradientTape() 的上下文内，所有计算步骤都会被记录以用于求导
with tf.GradientTape() as tape : y = tf.square(x)

y_grad = tape.gradient(y, x)        # 计算y关于x的导数
# 9, 6
print([y.numpy(), y_grad.numpy()])
```

这里 `x` 是一个初始化为3的 **变量** （Variable），使用 `tf.get_variable()` 声明。与普通张量一样，变量同样具有形状（shape）和类型（dtype）属性，不过使用变量需要有一个初始化过程，可以通过在 `tf.get_variable()` 中指定 `initializer` 参数来指定所使用的初始化器。这里使用 `tf.constant_initializer(3.)` 将变量 `x` 初始化为float32类型的 `3.` [[1\]](https://tf.wiki/zh/basic.html#f0)。变量与普通张量的一个重要区别是其默认能够被TensorFlow的自动求导机制所求导，因此往往被用于定义机器学习模型的参数。 `tf.GradientTape()` 是一个自动求导的记录器，在其中的变量和计算步骤都会被自动记录。上面的示例中，变量 `x` 和计算步骤 `y = tf.square(x)` 被自动记录，因此可以通过 `y_grad = tape.gradient(y, x)` 求张量 `y` 对变量 `x` 的导数。

在机器学习中，更加常见的是对多元函数求偏导数，以及对向量或矩阵的求导。这些对于TensorFlow也不在话下。以下代码展示了如何使用 `tf.GradientTape()` 计算函数 $L(w,b)=\|Xw+b-y\|^2$ 在 $w=(1,2)^\top,b=1$ 时分别对 $w,b$ 的偏导数。其中 $X = \left[ \begin{array} { l l } { 1 } & { 2 } \\ { 3 } & { 4 } \end{array} \right] , y = \left[ \begin{array} { l } { 1 } \\ { 2 } \end{array} \right]$。

```python
X = tf.constant([[1., 2.], [3., 4.]])
y = tf.constant([[1.], [2.]])
w = tf.get_variable('w', shape=[2, 1], initializer=tf.constant_initializer([[1.], [2.]]))
b = tf.get_variable('b', shape=[1], initializer=tf.constant_initializer([1.]))

with tf.GradientTape() as tape : L = 0.5 * tf.reduce_sum(tf.square(tf.matmul(X, w) + b - y))

w_grad, b_grad = tape.gradient(L, [w, b])        # 计算L(w, b)关于w, b的偏导数
print([L.numpy(), w_grad.numpy(), b_grad.numpy()])
```

这里， `tf.square()` 操作代表对输入张量的每一个元素求平方，不改变张量形状。 `tf.reduce_sum()`操作代表对输入张量的所有元素求和，输出一个形状为空的纯量张量（可以通过 `axis` 参数来指定求和的维度，不指定则默认对所有元素求和）。TensorFlow中有大量的张量操作API，包括数学运算、张量形状操作（如 `tf.reshape()`）、切片和连接（如 `tf.concat()`）等多种类型，可以通过查阅TensorFlow的官方API文档来进一步了解。

> 主要可以参考 [Tensor Transformations](https://www.tensorflow.org/versions/r1.9/api_guides/python/array_ops) 和 [Math](https://www.tensorflow.org/versions/r1.9/api_guides/python/math_ops) 两个页面。可以注意到，TensorFlow的张量操作API在形式上和Python下流行的科学计算库NumPy非常类似，如果对后者有所了解的话可以快速上手。

从输出可见，TensorFlow帮助我们计算出了
$$
\begin{aligned} L \left( ( 1,2 ) ^ { T } , 1 \right) & = 62.5 \\ \left. \frac { \partial L ( w , b ) } { \partial w } \right| _ { w = ( 1,2 ) ^ { T } , b = 1 } & = \left[ \begin{array} { c } { 35 } \\ { 50 } \end{array} \right] \\ \left. \frac { \partial L ( w , b ) } { \partial b } \right| _ { w = ( 1,2 ) ^ { T } , b = 1 } & = 15 \end{aligned}
$$
